{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2793ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2890848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_json(url, file_name):\n",
    "    try:\n",
    "        res = requests.get(url, timeout=5)\n",
    "        data = res.json()\n",
    "\n",
    "        with open(f'../data/{file_name}', 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        \n",
    "        print(f'Successfully saved JSON data: {file_name}')\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c019614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved JSON data: sf_tracts_new.geojson\n",
      "Successfully saved JSON data: sf_population_new.json\n",
      "Successfully saved JSON data: sf_water.geojson\n",
      "Successfully saved JSON data: bay_area_county_polygons.geojson\n",
      "Successfully saved JSON data: sfmta_routes.geojson\n"
     ]
    }
   ],
   "source": [
    "fetch_json('https://api.censusreporter.org/1.0/geo/show/latest?geo_ids=140|05000US06075&format=geojson', 'sf_tracts_new.geojson')\n",
    "fetch_json('https://api.censusreporter.org/1.0/data/show/latest?table_ids=B01003&geo_ids=140|05000US06075', 'sf_population_new.json')\n",
    "fetch_json('https://data.sfgov.org/resource/xgse-mjer.geojson', 'sf_water.geojson')\n",
    "fetch_json('https://data.sfgov.org/resource/wamw-vt4s.geojson', 'bay_area_county_polygons.geojson')\n",
    "fetch_json('https://data.sfgov.org/resource/9exe-acju.geojson', 'sfmta_routes.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d079e0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing...\n",
      "Loaded population JSON.\n",
      "Parsed population data into a DataFrame.\n",
      "Loaded census tract GeoJSON.\n",
      "Successfully merged population data with GeoJSON.\n",
      "Calculated area (sq miles) and population density (per sq mile).\n",
      "Projected final data back to WGS84.\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created final file: ../data/sf_tracts_with_density.geojson\n",
      "\n",
      "Preview of final data:\n",
      "                geoid                                    name  population  \\\n",
      "0  14000US06075010101  Census Tract 101.01, San Francisco, CA      2004.0   \n",
      "1  14000US06075010102  Census Tract 101.02, San Francisco, CA      1795.0   \n",
      "2  14000US06075010201  Census Tract 102.01, San Francisco, CA      2608.0   \n",
      "3  14000US06075010202  Census Tract 102.02, San Francisco, CA      1761.0   \n",
      "4  14000US06075010300     Census Tract 103, San Francisco, CA      3791.0   \n",
      "\n",
      "   area_sq_miles  population_density_sq_mi  \n",
      "0       0.518960               3861.572540  \n",
      "1       0.030726              58420.042081  \n",
      "2       0.072147              36148.254500  \n",
      "3       0.242356               7266.161679  \n",
      "4       0.103607              36590.249133  \n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define File Names ---\n",
    "population_json_file = \"../data/raw/sf_population.json\"\n",
    "tract_geojson_file = \"../data/raw/sf_tracts.geojson\"\n",
    "output_geojson_file = \"../data/sf_tracts_with_density.geojson\" \n",
    "\n",
    "print(\"Starting processing...\")\n",
    "\n",
    "try:\n",
    "    # --- 2. Load Population Data (JSON) ---\n",
    "    with open(population_json_file, 'r') as f:\n",
    "        pop_data = json.load(f)\n",
    "    print(\"Loaded population JSON.\")\n",
    "\n",
    "    # --- 3. Parse the Population JSON ---\n",
    "    POPULATION_KEY = 'B01003001'\n",
    "    population_list = []\n",
    "    \n",
    "    for geoid, tract_data in pop_data['data'].items():\n",
    "        try:\n",
    "            population = tract_data['B01003']['estimate'][POPULATION_KEY]\n",
    "            population_list.append({\n",
    "                'geoid': geoid,\n",
    "                'population': population\n",
    "            })\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Could not find population data for geoid {geoid}\")\n",
    "\n",
    "    pop_df = pd.DataFrame(population_list)\n",
    "    print(\"Parsed population data into a DataFrame.\")\n",
    "\n",
    "    # --- 4. Load Geographic Data (GeoJSON) ---\n",
    "    gdf_tracts = gpd.read_file(tract_geojson_file)\n",
    "    print(\"Loaded census tract GeoJSON.\")\n",
    "\n",
    "    # --- 5. Merge Population and Geographic Data ---\n",
    "    merged_gdf = gdf_tracts.merge(pop_df, on='geoid')\n",
    "    print(\"Successfully merged population data with GeoJSON.\")\n",
    "\n",
    "    # --- 6. Project, Calculate Area, and Calculate Density (IN SQ MILES) ---\n",
    "    projected_gdf = merged_gdf.to_crs(epsg=3310) # Project to meters\n",
    "    projected_gdf['area_sq_meters'] = projected_gdf.geometry.area\n",
    "    \n",
    "    # --- UPDATED CONVERSION ---\n",
    "    # 1 square kilometer = 0.386102 square miles\n",
    "    projected_gdf['area_sq_km'] = projected_gdf['area_sq_meters'] / 1_000_000\n",
    "    projected_gdf['area_sq_miles'] = projected_gdf['area_sq_km'] * 0.386102\n",
    "    \n",
    "    # --- UPDATED DENSITY CALCULATION ---\n",
    "    projected_gdf['population_density_sq_mi'] = projected_gdf.apply(\n",
    "        lambda row: row['population'] / row['area_sq_miles'] if row['area_sq_miles'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    print(\"Calculated area (sq miles) and population density (per sq mile).\")\n",
    "\n",
    "    # --- 7. Project back to WGS84 (EPSG:4326) for D3 ---\n",
    "    final_gdf = projected_gdf.to_crs(epsg=4326)\n",
    "    print(\"Projected final data back to WGS84.\")\n",
    "\n",
    "    # --- 8. Save the Final File (with new columns) ---\n",
    "    # --- UPDATED COLUMNS ---\n",
    "    columns_to_keep = [\n",
    "        'geometry',\n",
    "        'geoid',\n",
    "        'name',\n",
    "        'population',\n",
    "        'area_sq_miles', \n",
    "        'population_density_sq_mi' \n",
    "    ]\n",
    "    \n",
    "    final_gdf_clean = final_gdf[columns_to_keep]\n",
    "    final_gdf_clean.to_file(output_geojson_file, driver='GeoJSON')\n",
    "\n",
    "    print(\"\\n--- SUCCESS ---\")\n",
    "    print(f\"Successfully created final file: {output_geojson_file}\")\n",
    "    \n",
    "    print(\"\\nPreview of final data:\")\n",
    "    print(final_gdf_clean.drop(columns='geometry').head())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERROR: File not found. Make sure this file is in the same folder: {e.filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa333ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Bay Area file: ../data/bay_area_county_polygons.geojson...\n",
      "Found 'San Francisco' feature!\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created '../data/sf_county_boundary.geojson'\n",
      "This file is now ready to be used as your map's clipping mask.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "bay_area_file_name = \"../data/raw/bay_area_county_polygons.geojson\"\n",
    "output_file_name = \"../data/sf_county_boundary.geojson\"\n",
    "# --- End Configuration ---\n",
    "\n",
    "print(f\"Loading Bay Area file: {bay_area_file_name}...\")\n",
    "\n",
    "try:\n",
    "    # 1. Load the big Bay Area file\n",
    "    with open(bay_area_file_name, 'r') as f:\n",
    "        bay_area_data = json.load(f)\n",
    "\n",
    "    # 2. Find the San Francisco feature\n",
    "    sf_feature = None\n",
    "    for feature in bay_area_data['features']:\n",
    "        if feature.get('properties', {}).get('county') == 'San Francisco':\n",
    "            sf_feature = feature\n",
    "            print(\"Found 'San Francisco' feature!\")\n",
    "            break\n",
    "\n",
    "    if sf_feature:\n",
    "        # 3. Create a new, empty GeoJSON structure\n",
    "        # We copy the 'crs' (Coordinate Reference System) from the original\n",
    "        output_geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"crs\": bay_area_data.get('crs'), \n",
    "            \"features\": [sf_feature] # Add only the SF feature\n",
    "        }\n",
    "\n",
    "        # 5. Save the new, smaller file\n",
    "        with open(output_file_name, 'w') as f:\n",
    "            json.dump(output_geojson, f)\n",
    "            \n",
    "        print(f\"\\n--- SUCCESS ---\")\n",
    "        print(f\"Successfully created '{output_file_name}'\")\n",
    "        print(\"This file is now ready to be used as your map's clipping mask.\")\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Could not find a feature with 'county': 'San Francisco'\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file '{bay_area_file_name}'.\")\n",
    "    print(\"Please make sure it's in the same directory as this script.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "187a08c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/raw/sfmta_routes.geojson...\n",
      "File loaded. Searching for Geary routes...\n",
      "Found 4 features for routes: ['38', '38R']\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created '../data\\geary_route.geojson'\n",
      "This file contains the geometry for the 38 and 38R routes.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "routes_file = \"../data/raw/sfmta_routes.geojson\"\n",
    "output_file = \"geary_route.geojson\"\n",
    "output_folder = \"../data\" # Assumes you want to save it in your data folder\n",
    "# We'll focus on the main local and rapid routes\n",
    "routes_to_extract = ['38', '38R'] \n",
    "# --- End Configuration ---\n",
    "\n",
    "print(f\"Loading {routes_file}...\")\n",
    "\n",
    "try:\n",
    "    # Load the original routes file\n",
    "    with open(routes_file, 'r') as f:\n",
    "        routes_data = json.load(f)\n",
    "\n",
    "    print(\"File loaded. Searching for Geary routes...\")\n",
    "\n",
    "    # Create a list to hold the features we want to keep\n",
    "    geary_features = []\n",
    "    \n",
    "    # Check if 'features' key exists and is a list\n",
    "    if 'features' in routes_data and isinstance(routes_data['features'], list):\n",
    "        # Loop through all features\n",
    "        for feature in routes_data['features']:\n",
    "            if 'properties' in feature:\n",
    "                props = feature['properties']\n",
    "                \n",
    "                # Check if the 'route_name' is one we want\n",
    "                if props.get('route_name') in routes_to_extract:\n",
    "                    geary_features.append(feature)\n",
    "\n",
    "    if geary_features:\n",
    "        print(f\"Found {len(geary_features)} features for routes: {routes_to_extract}\")\n",
    "        \n",
    "        # Create a new, empty GeoJSON structure\n",
    "        # We copy the 'crs' (Coordinate Reference System) from the original\n",
    "        output_geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"crs\": routes_data.get('crs'), \n",
    "            \"features\": geary_features # Add only the Geary features\n",
    "        }\n",
    "\n",
    "        # 4. Make sure the 'data' folder exists\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "            print(f\"Created '{output_folder}' directory.\")\n",
    "\n",
    "        # 5. Save the new, smaller file\n",
    "        output_path = os.path.join(output_folder, output_file)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(output_geojson, f)\n",
    "            \n",
    "        print(f\"\\n--- SUCCESS ---\")\n",
    "        print(f\"Successfully created '{output_path}'\")\n",
    "        print(\"This file contains the geometry for the 38 and 38R routes.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"ERROR: Could not find any features for routes: {routes_to_extract}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file '{routes_file}'.\")\n",
    "    print(\"Please make sure it's in the same directory as this script.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/sfmta_routes.geojson...\n",
      "File loaded. Searching for Light Rail routes: ['J', 'K', 'L', 'M', 'N', 'T']\n",
      "Found 12 features for rail routes.\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created '../data\\sfmta_rail_lines.geojson'\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "routes_file = \"../data/raw/sfmta_routes.geojson\"\n",
    "output_file = \"sfmta_rail_lines.geojson\"\n",
    "output_folder = \"../data\"\n",
    "# These are the light rail lines\n",
    "routes_to_extract = ['J', 'K', 'L', 'M', 'N', 'T']\n",
    "# --- End Configuration ---\n",
    "\n",
    "print(f\"Loading {routes_file}...\")\n",
    "\n",
    "try:\n",
    "    with open(routes_file, 'r') as f:\n",
    "        routes_data = json.load(f)\n",
    "\n",
    "    print(f\"File loaded. Searching for Light Rail routes: {routes_to_extract}\")\n",
    "\n",
    "    rail_features = []\n",
    "    \n",
    "    if 'features' in routes_data and isinstance(routes_data['features'], list):\n",
    "        for feature in routes_data['features']:\n",
    "            if 'properties' in feature:\n",
    "                props = feature['properties']\n",
    "                if props.get('route_name') in routes_to_extract:\n",
    "                    rail_features.append(feature)\n",
    "\n",
    "    if rail_features:\n",
    "        print(f\"Found {len(rail_features)} features for rail routes.\")\n",
    "        \n",
    "        output_geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"crs\": routes_data.get('crs'), \n",
    "            \"features\": rail_features\n",
    "        }\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "            print(f\"Created '{output_folder}' directory.\")\n",
    "\n",
    "        output_path = os.path.join(output_folder, output_file)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(output_geojson, f)\n",
    "            \n",
    "        print(f\"\\n--- SUCCESS ---\")\n",
    "        print(f\"Successfully created '{output_path}'\")\n",
    "\n",
    "    else:\n",
    "        print(f\"ERROR: Could not find any rail line features.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file '{routes_file}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68377285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BART stations file: ../data/raw/bart_stations.geojson...\n",
      "Found 10 stations (SF + Daly City + West Oakland).\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created '../data\\sf_bart_stations.geojson'\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "bart_stations_file = \"../data/raw/bart_stations.geojson\"\n",
    "output_file_name = \"sf_bart_stations.geojson\"\n",
    "output_folder = \"../data\"\n",
    "\n",
    "# Stations to find\n",
    "# We use 'Name' for the non-SF ones just to be safe\n",
    "stations_to_keep = {\n",
    "    'City': ['San Francisco'],\n",
    "    'Name': ['Daly City', 'West Oakland']\n",
    "}\n",
    "# --- End Configuration ---\n",
    "\n",
    "print(f\"Loading BART stations file: {bart_stations_file}...\")\n",
    "\n",
    "try:\n",
    "    with open(bart_stations_file, 'r') as f:\n",
    "        bart_data = json.load(f)\n",
    "\n",
    "    sf_station_features = []\n",
    "    \n",
    "    if 'features' in bart_data and isinstance(bart_data['features'], list):\n",
    "        for feature in bart_data['features']:\n",
    "            props = feature.get('properties', {})\n",
    "            \n",
    "            # Check if it's an SF station OR one of our named stations\n",
    "            if (props.get('City') in stations_to_keep['City'] or \n",
    "                props.get('Name') in stations_to_keep['Name']):\n",
    "                \n",
    "                sf_station_features.append(feature)\n",
    "    \n",
    "    if sf_station_features:\n",
    "        print(f\"Found {len(sf_station_features)} stations (SF + Daly City + West Oakland).\")\n",
    "        \n",
    "        output_geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"crs\": bart_data.get('crs'), \n",
    "            \"features\": sf_station_features\n",
    "        }\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        output_path = os.path.join(output_folder, output_file_name)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(output_geojson, f)\n",
    "            \n",
    "        print(f\"\\n--- SUCCESS ---\")\n",
    "        print(f\"Successfully created '{output_path}'\")\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Could not find any of the target stations.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file '{bart_stations_file}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e7e9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/raw/sfmta_ridership.csv...\n",
      "Using data from the most recent full year: 2024\n",
      "\n",
      "--- Top 10 Corridors by Total Weekday Ridership (2024) ---\n",
      "           Corridor  Bus_Ridership  BART_Ridership  Total_Ridership       Highlight\n",
      "   Mission Corridor   46316.666667           12690     59006.666667 Other Corridors\n",
      "49 Van Ness/Mission   33925.000000           12690     46615.000000 Other Corridors\n",
      "     Geary Corridor   41808.333333               0     41808.333333  Geary Corridor\n",
      "        22 Fillmore   21783.333333               0     21783.333333 Other Corridors\n",
      "         8 Bayshore   17758.333333               0     17758.333333 Other Corridors\n",
      "       1 California   17408.333333               0     17408.333333 Other Corridors\n",
      "        30 Stockton   16391.666667               0     16391.666667 Other Corridors\n",
      "          29 Sunset   15400.000000               0     15400.000000 Other Corridors\n",
      "   44 O'Shaughnessy   12241.666667               0     12241.666667 Other Corridors\n",
      "   7 Haight/Noriega   10958.333333               0     10958.333333 Other Corridors\n",
      "\n",
      "Successfully created summary JSON file: ../data\\corridor_ridership_summary.json\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define File Names ---\n",
    "ridership_file = \"../data/raw/sfmta_ridership.csv\"\n",
    "output_file = \"corridor_ridership_summary.json\"\n",
    "output_folder = \"../data\"\n",
    "\n",
    "print(f\"Loading {ridership_file}...\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(ridership_file)\n",
    "\n",
    "    # --- 2. Clean Data ---\n",
    "    # Convert 'Average Daily Boardings' to a clean number\n",
    "    df['Average Daily Boardings'] = df['Average Daily Boardings'].str.replace(',', '')\n",
    "    df['Average Daily Boardings'] = pd.to_numeric(df['Average Daily Boardings'], errors='coerce')\n",
    "    df.dropna(subset=['Average Daily Boardings'], inplace=True)\n",
    "\n",
    "    # Convert 'Month' to datetime to find the year\n",
    "    df['Month'] = pd.to_datetime(df['Month'], format='%B %Y')\n",
    "    df['Year'] = df['Month'].dt.year\n",
    "    \n",
    "    # Use 2024 as the most recent full year\n",
    "    target_year = 2024\n",
    "    print(f\"Using data from the most recent full year: {target_year}\")\n",
    "    \n",
    "    # Filter for target year, weekdays, and only bus routes\n",
    "    non_bus_categories = ['Muni Metro', 'Cable Car', 'Historic Streetcar']\n",
    "    bus_df = df[\n",
    "        (df['Year'] == target_year) &\n",
    "        (df['Service Day of the Week'] == 'Weekday') &\n",
    "        (~df['Service Category'].isin(non_bus_categories))\n",
    "    ].copy()\n",
    "\n",
    "    # --- 3. Aggregate into Corridors ---\n",
    "    # Get the yearly average for each route\n",
    "    avg_annual_ridership = bus_df.groupby('Route')['Average Daily Boardings'].mean().reset_index()\n",
    "    \n",
    "    # Define corridor groups\n",
    "    corridor_map = {\n",
    "        '38 Geary': 'Geary Corridor',\n",
    "        '38R Geary Rapid': 'Geary Corridor',\n",
    "        '14 Mission': 'Mission Corridor',\n",
    "        '14R Mission Rapid': 'Mission Corridor',\n",
    "    }\n",
    "    \n",
    "    # Map routes to corridors, fill unmapped routes with their own name\n",
    "    avg_annual_ridership['Corridor'] = avg_annual_ridership['Route'].map(corridor_map).fillna(avg_annual_ridership['Route'])\n",
    "    \n",
    "    # Group by the new 'Corridor' and sum the boardings\n",
    "    corridor_totals = avg_annual_ridership.groupby('Corridor')['Average Daily Boardings'].sum().reset_index()\n",
    "    corridor_totals.rename(columns={'Average Daily Boardings': 'Bus_Ridership'}, inplace=True)\n",
    "\n",
    "    # --- 4. Manually Add BART Ridership Data ---\n",
    "    # Based on our analysis of BART data (16th St + 24th St)\n",
    "    BART_MISSION_RIDERSHIP = 12690\n",
    "    \n",
    "    corridor_totals['BART_Ridership'] = 0\n",
    "    \n",
    "    # Find the index for Mission Corridor and add BART ridership\n",
    "    mission_index = corridor_totals.index[corridor_totals['Corridor'] == 'Mission Corridor']\n",
    "    if not mission_index.empty:\n",
    "        corridor_totals.at[mission_index[0], 'BART_Ridership'] = BART_MISSION_RIDERSHIP\n",
    "\n",
    "    van_ness_index = corridor_totals.index[corridor_totals['Corridor'] == '49 Van Ness/Mission']\n",
    "    if not van_ness_index.empty:\n",
    "        corridor_totals.at[van_ness_index[0], 'BART_Ridership'] = BART_MISSION_RIDERSHIP\n",
    "    \n",
    "    # --- 5. Final Calculations and Sorting ---\n",
    "    corridor_totals['Total_Ridership'] = corridor_totals['Bus_Ridership'] + corridor_totals['BART_Ridership']\n",
    "    \n",
    "    # Get the Top 10 Corridors\n",
    "    top_10_corridors = corridor_totals.sort_values(by='Total_Ridership', ascending=False).head(10).copy()\n",
    "    \n",
    "    # Add a highlight column for D3\n",
    "    top_10_corridors['Highlight'] = top_10_corridors['Corridor'].apply(\n",
    "        lambda x: 'Geary Corridor' if 'Geary' in x else 'Other Corridors'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- Top 10 Corridors by Total Weekday Ridership (2024) ---\")\n",
    "    print(top_10_corridors.to_string(index=False))\n",
    "\n",
    "    # --- 6. Save to JSON for D3 ---\n",
    "    # Convert DataFrame to a list of dictionaries (records)\n",
    "    output_data = top_10_corridors.to_dict(orient='records')\n",
    "    \n",
    "    # Make sure 'data' folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(f\"Created '{output_folder}' directory.\")\n",
    "        \n",
    "    output_path = os.path.join(output_folder, output_file)\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "        \n",
    "    print(f\"\\nSuccessfully created summary JSON file: {output_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file '{ridership_file}'.\")\n",
    "    print(\"Please make sure it's in the same directory as this script.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a063d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frequent Local' 'Specialized' 'Grid' 'Rapid Bus' 'Connector' 'Cable Car'\n",
      " 'Owl' 'Historic' 'Muni Metro']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Route</th>\n",
       "      <th>Service Category</th>\n",
       "      <th>Service Day of the Week</th>\n",
       "      <th>Average Daily Boardings</th>\n",
       "      <th>Corridor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January 2019</td>\n",
       "      <td>1 California</td>\n",
       "      <td>Frequent Local</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9,600</td>\n",
       "      <td>1 California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 2019</td>\n",
       "      <td>1 California</td>\n",
       "      <td>Frequent Local</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>11,500</td>\n",
       "      <td>12 Folsom/Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March 2019</td>\n",
       "      <td>1 California</td>\n",
       "      <td>Frequent Local</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>11,800</td>\n",
       "      <td>14 Mission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April 2019</td>\n",
       "      <td>1 California</td>\n",
       "      <td>Frequent Local</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>10,800</td>\n",
       "      <td>14R Mission Rapid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May 2019</td>\n",
       "      <td>1 California</td>\n",
       "      <td>Frequent Local</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>10,800</td>\n",
       "      <td>15 Bayview Hunters Point Express</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11756</th>\n",
       "      <td>June 2025</td>\n",
       "      <td>67 Bernal Heights</td>\n",
       "      <td>Connector</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11757</th>\n",
       "      <td>July 2025</td>\n",
       "      <td>67 Bernal Heights</td>\n",
       "      <td>Connector</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11758</th>\n",
       "      <td>August 2025</td>\n",
       "      <td>67 Bernal Heights</td>\n",
       "      <td>Connector</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11759</th>\n",
       "      <td>September 2025</td>\n",
       "      <td>67 Bernal Heights</td>\n",
       "      <td>Connector</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11760</th>\n",
       "      <td>October 2025</td>\n",
       "      <td>67 Bernal Heights</td>\n",
       "      <td>Connector</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9488 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Month              Route Service Category  \\\n",
       "0        January 2019       1 California   Frequent Local   \n",
       "1       February 2019       1 California   Frequent Local   \n",
       "2          March 2019       1 California   Frequent Local   \n",
       "3          April 2019       1 California   Frequent Local   \n",
       "4            May 2019       1 California   Frequent Local   \n",
       "...               ...                ...              ...   \n",
       "11756       June 2025  67 Bernal Heights        Connector   \n",
       "11757       July 2025  67 Bernal Heights        Connector   \n",
       "11758     August 2025  67 Bernal Heights        Connector   \n",
       "11759  September 2025  67 Bernal Heights        Connector   \n",
       "11760    October 2025  67 Bernal Heights        Connector   \n",
       "\n",
       "      Service Day of the Week Average Daily Boardings  \\\n",
       "0                      Sunday                   9,600   \n",
       "1                      Sunday                  11,500   \n",
       "2                      Sunday                  11,800   \n",
       "3                      Sunday                  10,800   \n",
       "4                      Sunday                  10,800   \n",
       "...                       ...                     ...   \n",
       "11756                 Weekday                     700   \n",
       "11757                 Weekday                     700   \n",
       "11758                 Weekday                     800   \n",
       "11759                 Weekday                     900   \n",
       "11760                 Weekday                     800   \n",
       "\n",
       "                               Corridor  \n",
       "0                          1 California  \n",
       "1                     12 Folsom/Pacific  \n",
       "2                            14 Mission  \n",
       "3                     14R Mission Rapid  \n",
       "4      15 Bayview Hunters Point Express  \n",
       "...                                 ...  \n",
       "11756                               NaN  \n",
       "11757                               NaN  \n",
       "11758                               NaN  \n",
       "11759                               NaN  \n",
       "11760                               NaN  \n",
       "\n",
       "[9488 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
