{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2793ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2890848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_json(url, file_name):\n",
    "    try:\n",
    "        res = requests.get(url, timeout=5)\n",
    "        data = res.json()\n",
    "\n",
    "        with open(f'../data/{file_name}', 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        \n",
    "        print(f'Successfully saved JSON data: {file_name}')\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c019614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved JSON data: sf_tracts_new.geojson\n",
      "Successfully saved JSON data: sf_population_new.json\n",
      "Successfully saved JSON data: sf_water.geojson\n",
      "Successfully saved JSON data: bay_area_county_polygons.geojson\n",
      "Successfully saved JSON data: sfmta_routes.geojson\n"
     ]
    }
   ],
   "source": [
    "fetch_json('https://api.censusreporter.org/1.0/geo/show/latest?geo_ids=140|05000US06075&format=geojson', 'sf_tracts_new.geojson')\n",
    "fetch_json('https://api.censusreporter.org/1.0/data/show/latest?table_ids=B01003&geo_ids=140|05000US06075', 'sf_population_new.json')\n",
    "fetch_json('https://data.sfgov.org/resource/xgse-mjer.geojson', 'sf_water.geojson')\n",
    "fetch_json('https://data.sfgov.org/resource/wamw-vt4s.geojson', 'bay_area_county_polygons.geojson')\n",
    "fetch_json('https://data.sfgov.org/resource/9exe-acju.geojson', 'sfmta_routes.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d079e0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing...\n",
      "Loaded population JSON.\n",
      "Parsed population data into a DataFrame.\n",
      "Loaded census tract GeoJSON.\n",
      "Successfully merged population data with GeoJSON.\n",
      "Calculated area (sq miles) and population density (per sq mile).\n",
      "Projected final data back to WGS84.\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created final file: ../data/sf_tracts_with_density.geojson\n",
      "\n",
      "Preview of final data:\n",
      "                geoid                                    name  population  \\\n",
      "0  14000US06075010101  Census Tract 101.01, San Francisco, CA      2004.0   \n",
      "1  14000US06075010102  Census Tract 101.02, San Francisco, CA      1795.0   \n",
      "2  14000US06075010201  Census Tract 102.01, San Francisco, CA      2608.0   \n",
      "3  14000US06075010202  Census Tract 102.02, San Francisco, CA      1761.0   \n",
      "4  14000US06075010300     Census Tract 103, San Francisco, CA      3791.0   \n",
      "\n",
      "   area_sq_miles  population_density_sq_mi  \n",
      "0       0.518960               3861.572540  \n",
      "1       0.030726              58420.042081  \n",
      "2       0.072147              36148.254500  \n",
      "3       0.242356               7266.161679  \n",
      "4       0.103607              36590.249133  \n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define File Names ---\n",
    "population_json_file = \"../data/sf_population_new.json\"\n",
    "tract_geojson_file = \"../data/sf_tracts_new.geojson\"\n",
    "output_geojson_file = \"../data/sf_tracts_with_density.geojson\" \n",
    "\n",
    "print(\"Starting processing...\")\n",
    "\n",
    "try:\n",
    "    # --- 2. Load Population Data (JSON) ---\n",
    "    with open(population_json_file, 'r') as f:\n",
    "        pop_data = json.load(f)\n",
    "    print(\"Loaded population JSON.\")\n",
    "\n",
    "    # --- 3. Parse the Population JSON ---\n",
    "    POPULATION_KEY = 'B01003001'\n",
    "    population_list = []\n",
    "    \n",
    "    for geoid, tract_data in pop_data['data'].items():\n",
    "        try:\n",
    "            population = tract_data['B01003']['estimate'][POPULATION_KEY]\n",
    "            population_list.append({\n",
    "                'geoid': geoid,\n",
    "                'population': population\n",
    "            })\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Could not find population data for geoid {geoid}\")\n",
    "\n",
    "    pop_df = pd.DataFrame(population_list)\n",
    "    print(\"Parsed population data into a DataFrame.\")\n",
    "\n",
    "    # --- 4. Load Geographic Data (GeoJSON) ---\n",
    "    gdf_tracts = gpd.read_file(tract_geojson_file)\n",
    "    print(\"Loaded census tract GeoJSON.\")\n",
    "\n",
    "    # --- 5. Merge Population and Geographic Data ---\n",
    "    merged_gdf = gdf_tracts.merge(pop_df, on='geoid')\n",
    "    print(\"Successfully merged population data with GeoJSON.\")\n",
    "\n",
    "    # --- 6. Project, Calculate Area, and Calculate Density (IN SQ MILES) ---\n",
    "    projected_gdf = merged_gdf.to_crs(epsg=3310) # Project to meters\n",
    "    projected_gdf['area_sq_meters'] = projected_gdf.geometry.area\n",
    "    \n",
    "    # --- UPDATED CONVERSION ---\n",
    "    # 1 square kilometer = 0.386102 square miles\n",
    "    projected_gdf['area_sq_km'] = projected_gdf['area_sq_meters'] / 1_000_000\n",
    "    projected_gdf['area_sq_miles'] = projected_gdf['area_sq_km'] * 0.386102\n",
    "    \n",
    "    # --- UPDATED DENSITY CALCULATION ---\n",
    "    projected_gdf['population_density_sq_mi'] = projected_gdf.apply(\n",
    "        lambda row: row['population'] / row['area_sq_miles'] if row['area_sq_miles'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    print(\"Calculated area (sq miles) and population density (per sq mile).\")\n",
    "\n",
    "    # --- 7. Project back to WGS84 (EPSG:4326) for D3 ---\n",
    "    final_gdf = projected_gdf.to_crs(epsg=4326)\n",
    "    print(\"Projected final data back to WGS84.\")\n",
    "\n",
    "    # --- 8. Save the Final File (with new columns) ---\n",
    "    # --- UPDATED COLUMNS ---\n",
    "    columns_to_keep = [\n",
    "        'geometry',\n",
    "        'geoid',\n",
    "        'name',\n",
    "        'population',\n",
    "        'area_sq_miles', \n",
    "        'population_density_sq_mi' \n",
    "    ]\n",
    "    \n",
    "    final_gdf_clean = final_gdf[columns_to_keep]\n",
    "    final_gdf_clean.to_file(output_geojson_file, driver='GeoJSON')\n",
    "\n",
    "    print(\"\\n--- SUCCESS ---\")\n",
    "    print(f\"Successfully created final file: {output_geojson_file}\")\n",
    "    \n",
    "    print(\"\\nPreview of final data:\")\n",
    "    print(final_gdf_clean.drop(columns='geometry').head())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERROR: File not found. Make sure this file is in the same folder: {e.filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baa333ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Bay Area file: ../data/bay_area_county_polygons.geojson...\n",
      "Found 'San Francisco' feature!\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created '../data/sf_county_boundary.geojson'\n",
      "This file is now ready to be used as your map's clipping mask.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "bay_area_file_name = \"../data/bay_area_county_polygons.geojson\"\n",
    "output_file_name = \"../data/sf_county_boundary.geojson\"\n",
    "# --- End Configuration ---\n",
    "\n",
    "print(f\"Loading Bay Area file: {bay_area_file_name}...\")\n",
    "\n",
    "try:\n",
    "    # 1. Load the big Bay Area file\n",
    "    with open(bay_area_file_name, 'r') as f:\n",
    "        bay_area_data = json.load(f)\n",
    "\n",
    "    # 2. Find the San Francisco feature\n",
    "    sf_feature = None\n",
    "    for feature in bay_area_data['features']:\n",
    "        if feature.get('properties', {}).get('county') == 'San Francisco':\n",
    "            sf_feature = feature\n",
    "            print(\"Found 'San Francisco' feature!\")\n",
    "            break\n",
    "\n",
    "    if sf_feature:\n",
    "        # 3. Create a new, empty GeoJSON structure\n",
    "        # We copy the 'crs' (Coordinate Reference System) from the original\n",
    "        output_geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"crs\": bay_area_data.get('crs'), \n",
    "            \"features\": [sf_feature] # Add only the SF feature\n",
    "        }\n",
    "\n",
    "        # 5. Save the new, smaller file\n",
    "        with open(output_file_name, 'w') as f:\n",
    "            json.dump(output_geojson, f)\n",
    "            \n",
    "        print(f\"\\n--- SUCCESS ---\")\n",
    "        print(f\"Successfully created '{output_file_name}'\")\n",
    "        print(\"This file is now ready to be used as your map's clipping mask.\")\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Could not find a feature with 'county': 'San Francisco'\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file '{bay_area_file_name}'.\")\n",
    "    print(\"Please make sure it's in the same directory as this script.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "187a08c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/sfmta_routes.geojson...\n",
      "File loaded. Searching for Geary routes...\n",
      "Found 4 features for routes: ['38', '38R']\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created '../data\\geary_route.geojson'\n",
      "This file contains the geometry for the 38 and 38R routes.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "routes_file = \"../data/sfmta_routes.geojson\"\n",
    "output_file = \"geary_route.geojson\"\n",
    "output_folder = \"../data\" # Assumes you want to save it in your data folder\n",
    "# We'll focus on the main local and rapid routes\n",
    "routes_to_extract = ['38', '38R'] \n",
    "# --- End Configuration ---\n",
    "\n",
    "print(f\"Loading {routes_file}...\")\n",
    "\n",
    "try:\n",
    "    # Load the original routes file\n",
    "    with open(routes_file, 'r') as f:\n",
    "        routes_data = json.load(f)\n",
    "\n",
    "    print(\"File loaded. Searching for Geary routes...\")\n",
    "\n",
    "    # Create a list to hold the features we want to keep\n",
    "    geary_features = []\n",
    "    \n",
    "    # Check if 'features' key exists and is a list\n",
    "    if 'features' in routes_data and isinstance(routes_data['features'], list):\n",
    "        # Loop through all features\n",
    "        for feature in routes_data['features']:\n",
    "            if 'properties' in feature:\n",
    "                props = feature['properties']\n",
    "                \n",
    "                # Check if the 'route_name' is one we want\n",
    "                if props.get('route_name') in routes_to_extract:\n",
    "                    geary_features.append(feature)\n",
    "\n",
    "    if geary_features:\n",
    "        print(f\"Found {len(geary_features)} features for routes: {routes_to_extract}\")\n",
    "        \n",
    "        # Create a new, empty GeoJSON structure\n",
    "        # We copy the 'crs' (Coordinate Reference System) from the original\n",
    "        output_geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"crs\": routes_data.get('crs'), \n",
    "            \"features\": geary_features # Add only the Geary features\n",
    "        }\n",
    "\n",
    "        # 4. Make sure the 'data' folder exists\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "            print(f\"Created '{output_folder}' directory.\")\n",
    "\n",
    "        # 5. Save the new, smaller file\n",
    "        output_path = os.path.join(output_folder, output_file)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(output_geojson, f)\n",
    "            \n",
    "        print(f\"\\n--- SUCCESS ---\")\n",
    "        print(f\"Successfully created '{output_path}'\")\n",
    "        print(\"This file contains the geometry for the 38 and 38R routes.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"ERROR: Could not find any features for routes: {routes_to_extract}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file '{routes_file}'.\")\n",
    "    print(\"Please make sure it's in the same directory as this script.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c17dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/sfmta_routes.geojson...\n",
      "File loaded. Searching for Light Rail routes: ['J', 'K', 'L', 'M', 'N', 'T']\n",
      "Found 12 features for rail routes.\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created '../data\\sfmta_rail_lines.geojson'\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "routes_file = \"../data/sfmta_routes.geojson\"\n",
    "output_file = \"sfmta_rail_lines.geojson\"\n",
    "output_folder = \"../data\"\n",
    "# These are the light rail lines\n",
    "routes_to_extract = ['J', 'K', 'L', 'M', 'N', 'T']\n",
    "# --- End Configuration ---\n",
    "\n",
    "print(f\"Loading {routes_file}...\")\n",
    "\n",
    "try:\n",
    "    with open(routes_file, 'r') as f:\n",
    "        routes_data = json.load(f)\n",
    "\n",
    "    print(f\"File loaded. Searching for Light Rail routes: {routes_to_extract}\")\n",
    "\n",
    "    rail_features = []\n",
    "    \n",
    "    if 'features' in routes_data and isinstance(routes_data['features'], list):\n",
    "        for feature in routes_data['features']:\n",
    "            if 'properties' in feature:\n",
    "                props = feature['properties']\n",
    "                if props.get('route_name') in routes_to_extract:\n",
    "                    rail_features.append(feature)\n",
    "\n",
    "    if rail_features:\n",
    "        print(f\"Found {len(rail_features)} features for rail routes.\")\n",
    "        \n",
    "        output_geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"crs\": routes_data.get('crs'), \n",
    "            \"features\": rail_features\n",
    "        }\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "            print(f\"Created '{output_folder}' directory.\")\n",
    "\n",
    "        output_path = os.path.join(output_folder, output_file)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(output_geojson, f)\n",
    "            \n",
    "        print(f\"\\n--- SUCCESS ---\")\n",
    "        print(f\"Successfully created '{output_path}'\")\n",
    "\n",
    "    else:\n",
    "        print(f\"ERROR: Could not find any rail line features.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file '{routes_file}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68377285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BART stations file: ../data/bart_stations.geojson...\n",
      "Found 8 San Francisco BART stations.\n",
      "\n",
      "--- SUCCESS ---\n",
      "Successfully created '../data\\sf_bart_stations.geojson'\n",
      "This file contains only the 8 SF BART stations.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "bart_stations_file = \"../data/bart_stations.geojson\"\n",
    "output_file_name = \"sf_bart_stations.geojson\"\n",
    "output_folder = \"../data\"\n",
    "# --- End Configuration ---\n",
    "\n",
    "print(f\"Loading BART stations file: {bart_stations_file}...\")\n",
    "\n",
    "try:\n",
    "    # 1. Load the original BART stations file\n",
    "    with open(bart_stations_file, 'r') as f:\n",
    "        bart_data = json.load(f)\n",
    "\n",
    "    # 2. Find the San Francisco features\n",
    "    sf_station_features = []\n",
    "    \n",
    "    if 'features' in bart_data and isinstance(bart_data['features'], list):\n",
    "        for feature in bart_data['features']:\n",
    "            if feature.get('properties', {}).get('City') == 'San Francisco':\n",
    "                sf_station_features.append(feature)\n",
    "    \n",
    "    if sf_station_features:\n",
    "        print(f\"Found {len(sf_station_features)} San Francisco BART stations.\")\n",
    "        \n",
    "        # 3. Create a new, empty GeoJSON structure\n",
    "        output_geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"crs\": bart_data.get('crs'), \n",
    "            \"features\": sf_station_features # Add only the SF features\n",
    "        }\n",
    "\n",
    "        # 4. Make sure the 'data' folder exists\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "            print(f\"Created '{output_folder}' directory.\")\n",
    "\n",
    "        # 5. Save the new, smaller file\n",
    "        output_path = os.path.join(output_folder, output_file_name)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(output_geojson, f)\n",
    "            \n",
    "        print(f\"\\n--- SUCCESS ---\")\n",
    "        print(f\"Successfully created '{output_path}'\")\n",
    "        print(\"This file contains only the 8 SF BART stations.\")\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Could not find any features with 'City': 'San Francisco'\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the file '{bart_stations_file}'.\")\n",
    "    print(\"Please make sure it's in the same directory as this script.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "935ba45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/sfmta_ridership.csv...\n",
      "Using data from 2025...\n",
      "\n",
      "--- Top Bus Routes by Avg. Daily Weekday Boardings (2025) ---\n",
      "              Route  Average Daily Boardings\n",
      "49 Van Ness/Mission                  35040.0\n",
      "    38R Geary Rapid                  26510.0\n",
      "         14 Mission                  23150.0\n",
      "  14R Mission Rapid                  23080.0\n",
      "        22 Fillmore                  22490.0\n",
      "       1 California                  18620.0\n",
      "         8 Bayshore                  18240.0\n",
      "           38 Geary                  17740.0\n",
      "          29 Sunset                  15940.0\n",
      "        30 Stockton                  15530.0\n",
      "   44 O'Shaughnessy                  12740.0\n",
      "   7 Haight/Noriega                  12190.0\n",
      "     28 19th Avenue                  11210.0\n",
      "      24 Divisadero                  11130.0\n",
      "  45 Union/Stockton                  10460.0\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "ridership_file = \"../data/sfmta_ridership.csv\"\n",
    "print(f\"Loading {ridership_file}...\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(ridership_file)\n",
    "\n",
    "    # --- 1. Clean Average Daily Boardings ---\n",
    "    df['Average Daily Boardings'] = df['Average Daily Boardings'].astype(str).str.replace(',', '')\n",
    "    df['Average Daily Boardings'] = pd.to_numeric(df['Average Daily Boardings'], errors='coerce')\n",
    "    df.dropna(subset=['Average Daily Boardings'], inplace=True)\n",
    "    df['Average Daily Boardings'] = df['Average Daily Boardings'].astype(int)\n",
    "\n",
    "    # --- 2. Clean and Filter by Date ---\n",
    "    df['Month'] = pd.to_datetime(df['Month'], format='%B %Y')\n",
    "    df['Year'] = df['Month'].dt.year\n",
    "    \n",
    "    # Use 2024 as the most recent full year (from our last analysis)\n",
    "    target_year = 2025\n",
    "    print(f\"Using data from {target_year}...\")\n",
    "    \n",
    "    # --- 3. Filter for Weekday Bus Routes ---\n",
    "    \n",
    "    # Define non-bus categories to exclude\n",
    "    # This is more reliable than regex\n",
    "    non_bus_categories = ['Muni Metro', 'Cable Car', 'Historic Streetcar']\n",
    "    \n",
    "    # Filter for the target year, weekdays, and ONLY bus routes\n",
    "    bus_df = df[\n",
    "        (df['Year'] == target_year) &\n",
    "        (df['Service Day of the Week'] == 'Weekday') &\n",
    "        (~df['Service Category'].isin(non_bus_categories))\n",
    "    ].copy()\n",
    "\n",
    "    # --- 4. Analyze Ridership ---\n",
    "    # Calculate the average boardings for the entire year\n",
    "    avg_annual_ridership = bus_df.groupby('Route')['Average Daily Boardings'].mean().reset_index()\n",
    "    \n",
    "    # Sort to find the top routes\n",
    "    top_bus_routes = avg_annual_ridership.sort_values(by='Average Daily Boardings', ascending=False)\n",
    "    \n",
    "    print(f\"\\n--- Top Bus Routes by Avg. Daily Weekday Boardings ({target_year}) ---\")\n",
    "    print(top_bus_routes.head(15).to_string(index=False))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
